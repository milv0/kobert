{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff78aacf-5d87-42f9-a0ac-4cb64342a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kobert-wellness-chatbot\n"
     ]
    }
   ],
   "source": [
    "# import문 보고 필요한 pip들 수동으로 설치하기 (requirements 하면 오류 많이 날수도)\n",
    "# torch 최신버전이면 다 될듯!\n",
    "!pwd\n",
    "\n",
    "!mkdir checkpoint\n",
    "!mkdir data\n",
    "# 폴더 만들어졌으면 구글 드라이브에서 다운로드 \n",
    "# model-v3 사용하면 됨 (임시로 epoch30으로 학습된 것)\n",
    "# 구글 드라이브 url : https://drive.google.com/drive/folders/1rmU70p2WEGA0sLhsw9WYowXrTj1y7M_g?usp=sharing\n",
    "\n",
    "# checkpoint 폴더 -> 모델 저장 (model-v3)\n",
    "# data 폴더 -> txt 파일들 저장(category, answer_v2 / input_v2는 학습할 때 사용해서 다운 안받아도 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd7de7-3560-43d4-8cdf-348f534e7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "from model.classifier import KoBERTforSequenceClassfication\n",
    "from kobert_transformers import get_tokenizer\n",
    "from model.dataloader import WellnessTextClassificationDataset\n",
    "\n",
    "# warning 출력 안되게\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d582d8-ba61-4ab7-9998-e67e2991eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 경로 지정\n",
    "root_path = \".\"\n",
    "category_path = f\"{root_path}/data/category.txt\"\n",
    "answer_path = f\"{root_path}/data/answer_v2.txt\"\n",
    "checkpoint_path = f\"{root_path}/checkpoint/model-v3.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c63eaa-101d-42f2-96bf-a0529e7b4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wellness_answer():\n",
    "\n",
    "    c_f = open(category_path, 'r')\n",
    "    a_f = open(answer_path, 'r')\n",
    "\n",
    "    category_lines = c_f.readlines()\n",
    "    answer_lines = a_f.readlines()\n",
    "\n",
    "    category = {}\n",
    "    answer = {}\n",
    "    for line_num, line_data in enumerate(category_lines):\n",
    "        data = line_data.split('    ')\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in category file at line {line_num}: {line_data}\")\n",
    "        category[data[1][:-1]] = data[0]\n",
    "\n",
    "    for line_num, line_data in enumerate(answer_lines):\n",
    "        data = line_data.split('    ')\n",
    "        keys = answer.keys()\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in answer file at line {line_num}: {line_data}\")\n",
    "        if (data[0] in keys):\n",
    "            answer[data[0]] += [data[1][:-1]]\n",
    "        else:\n",
    "            answer[data[0]] = [data[1][:-1]]\n",
    "\n",
    "    return category, answer\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = KoBERTforSequenceClassfication()\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    tokenizer = get_tokenizer()\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def preprocess_input(tokenizer, sent, device, max_seq_len=512):\n",
    "    index_of_words = tokenizer.encode(sent)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd28d5b-1e00-4ded-a175-341a6ac42c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(category, answer, output):\n",
    "    softmax_logit = torch.softmax(output[0], dim=-1).squeeze()\n",
    "    max_index = torch.argmax(softmax_logit).item()\n",
    "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "    if str(max_index) in category:\n",
    "        answer_category = category[str(max_index)]\n",
    "        answer_list = answer[category[str(max_index)]]\n",
    "        answer_len = len(answer_list) - 1\n",
    "        \n",
    "        # 랜덤으로 답변을 불러와서 수정 필요....\n",
    "        answer_index = random.randint(0, answer_len)\n",
    "        return answer_list[answer_index], answer_category, max_index_value\n",
    "    else:\n",
    "        return \"키가 딕셔너리에 존재하지 않습니다.\", None, max_index_value\n",
    "\n",
    "def chatbot_main(checkpoint_path, category, answer):\n",
    "    model, tokenizer, device = load_model(checkpoint_path)\n",
    "    while True:\n",
    "        # 터미널에서 한글 입력할 때 띄어쓰기나 백스페이스 누르면 문자열 못읽고 종료되는 경우 있음\n",
    "        # 수정할 예정\n",
    "        sent1 = input('\\nQuestion: ')\n",
    "        sent = str(sent1)\n",
    "        if '종료' in sent:\n",
    "            break\n",
    "        if '안녕?' in sent or '안녕!' in sent or '안녕' in sent:\n",
    "            print('Answer : 반가워요! 저는 기룡이에요!')\n",
    "            continue\n",
    "        data = preprocess_input(tokenizer, sent, device, 512)\n",
    "        output = model(**data)\n",
    "        answer, category, max_index_value = get_answer(category, answer, output)\n",
    "        print(f'Answer: {answer} \\nindex: {category},{max_index_value} \\nsoftmax_value: {max_index_value}')\n",
    "        print('-' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6016bcb0-2d64-4776-94b4-0aa31eac898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category, answer = load_wellness_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e17e57-0ee8-4a3f-982f-df798841dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 실행\n",
    "chatbot_main(checkpoint_path, category, answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
