{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff78aacf-5d87-42f9-a0ac-4cb64342a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kobert-wellness-chatbot\n"
     ]
    }
   ],
   "source": [
    "# 구글 드라이브 url(학습된 모델) :\n",
    "# 구글 드라이브 url(txt 데이터들) :\n",
    "\n",
    "# checkpoint 폴더 -> 모델 저장\n",
    "# data 폴더 -> txt 파일들 저장\n",
    "\n",
    "# import문 보고 필요한 pip들 수동으로 설치하기 (requirements 하면 오류 많이 날수도)\n",
    "\n",
    "# model 폴더 안 dataloader.py 에서 file_path 에 input 데이터 경로 맞는지 확인!!!! \n",
    "# category 추가 시 dataloader.py/ classifier.py 에서 num_labels 수정 필요 (카테고리 개수 맞게_현재 432)\n",
    "!pwd\n",
    "\n",
    "!mkdir checkpoint\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd7de7-3560-43d4-8cdf-348f534e7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "from model.classifier import KoBERTforSequenceClassfication\n",
    "from kobert_transformers import get_tokenizer\n",
    "from model.dataloader import WellnessTextClassificationDataset\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d582d8-ba61-4ab7-9998-e67e2991eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \".\"\n",
    "category_path = f\"{root_path}/data/category.txt\"\n",
    "answer_path = f\"{root_path}/data/answer_v2.txt\"\n",
    "checkpoint_path = f\"{root_path}/checkpoint/model-v3.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c63eaa-101d-42f2-96bf-a0529e7b4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wellness_answer():\n",
    "\n",
    "    c_f = open(category_path, 'r')\n",
    "    a_f = open(answer_path, 'r')\n",
    "\n",
    "    category_lines = c_f.readlines()\n",
    "    answer_lines = a_f.readlines()\n",
    "\n",
    "    category = {}\n",
    "    answer = {}\n",
    "    for line_num, line_data in enumerate(category_lines):\n",
    "        data = line_data.split('    ')\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in category file at line {line_num}: {line_data}\")\n",
    "        category[data[1][:-1]] = data[0]\n",
    "\n",
    "    for line_num, line_data in enumerate(answer_lines):\n",
    "        data = line_data.split('    ')\n",
    "        keys = answer.keys()\n",
    "        if len(data) != 2:\n",
    "            print(f\"Error in answer file at line {line_num}: {line_data}\")\n",
    "        if (data[0] in keys):\n",
    "            answer[data[0]] += [data[1][:-1]]\n",
    "        else:\n",
    "            answer[data[0]] = [data[1][:-1]]\n",
    "\n",
    "    return category, answer\n",
    "\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = KoBERTforSequenceClassfication()\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    tokenizer = get_tokenizer()\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def preprocess_input(tokenizer, sent, device, max_seq_len=512):\n",
    "    index_of_words = tokenizer.encode(sent)\n",
    "    token_type_ids = [0] * len(index_of_words)\n",
    "    attention_mask = [1] * len(index_of_words)\n",
    "    padding_length = max_seq_len - len(index_of_words)\n",
    "    index_of_words += [0] * padding_length\n",
    "    token_type_ids += [0] * padding_length\n",
    "    attention_mask += [0] * padding_length\n",
    "    data = {\n",
    "        'input_ids': torch.tensor([index_of_words]).to(device),\n",
    "        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n",
    "        'attention_mask': torch.tensor([attention_mask]).to(device),\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd28d5b-1e00-4ded-a175-341a6ac42c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(category, answer, output):\n",
    "    softmax_logit = torch.softmax(output[0], dim=-1).squeeze()\n",
    "    max_index = torch.argmax(softmax_logit).item()\n",
    "    max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n",
    "    if str(max_index) in category:\n",
    "        answer_category = category[str(max_index)]\n",
    "        answer_list = answer[category[str(max_index)]]\n",
    "        answer_len = len(answer_list) - 1\n",
    "        answer_index = random.randint(0, answer_len)\n",
    "        return answer_list[answer_index], answer_category, max_index_value\n",
    "    else:\n",
    "        return \"키가 딕셔너리에 존재하지 않습니다.\", None, max_index_value\n",
    "\n",
    "def chatbot_main(checkpoint_path, category, answer):\n",
    "    model, tokenizer, device = load_model(checkpoint_path)\n",
    "    while True:\n",
    "        sent1 = input('\\nQuestion: ')\n",
    "        sent = str(sent1)\n",
    "        if '종료' in sent:\n",
    "            break\n",
    "        if '안녕?' in sent or '안녕!' in sent or '안녕' in sent:\n",
    "            print('Answer : 반가워요! 저는 기룡이에요!')\n",
    "            continue\n",
    "        data = preprocess_input(tokenizer, sent, device, 512)\n",
    "        output = model(**data)\n",
    "        answer, category, max_index_value = get_answer(category, answer, output)\n",
    "        print(f'Answer: {answer} \\nindex: {category},{max_index_value} \\nsoftmax_value: {max_index_value}')\n",
    "        print('-' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6016bcb0-2d64-4776-94b4-0aa31eac898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category, answer = load_wellness_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5285be4-4521-4187-9701-2d7f599024a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:  공황장애가 오는거 같아\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 너무 자책하지 마세요. 우리는 모두 실수를 하고, 어려운 시기를 겪을 때가 있어요. 그런 순간들을 통해 배우고成長합니다. \n",
      "index: 감정/자괴감,0.07159240543842316 \n",
      "softmax_value: 0.07159240543842316\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:  공황발작이 오는거 같아\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 키가 딕셔너리에 존재하지 않습니다. \n",
      "index: None,0.14692756533622742 \n",
      "softmax_value: 0.14692756533622742\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:  공황이 오는거 같아\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 챗봇 실행\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchatbot_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mchatbot_main\u001b[0;34m(checkpoint_path, category, answer)\u001b[0m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m preprocess_input(tokenizer, sent, device, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     12\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 13\u001b[0m answer, category, max_index_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mindex: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_index_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msoftmax_value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_index_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(category, answer, output)\u001b[0m\n\u001b[1;32m     57\u001b[0m max_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(softmax_logit)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     58\u001b[0m max_index_value \u001b[38;5;241m=\u001b[39m softmax_logit[torch\u001b[38;5;241m.\u001b[39margmax(softmax_logit)]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m:\n\u001b[1;32m     60\u001b[0m     answer_category \u001b[38;5;241m=\u001b[39m category[\u001b[38;5;28mstr\u001b[39m(max_index)]\n\u001b[1;32m     61\u001b[0m     answer_list \u001b[38;5;241m=\u001b[39m answer[category[\u001b[38;5;28mstr\u001b[39m(max_index)]]\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "# 챗봇 실행\n",
    "chatbot_main(checkpoint_path, category, answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
